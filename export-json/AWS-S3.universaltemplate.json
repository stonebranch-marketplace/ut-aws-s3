{
    "agent": null,
    "agentCluster": null,
    "agentClusterVar": null,
    "agentFieldsRestriction": "No Restriction",
    "agentType": "Any",
    "agentVar": null,
    "automaticOutputRetrievalFieldsRestriction": "No Restriction",
    "broadcastCluster": null,
    "broadcastClusterVar": null,
    "createConsole": false,
    "credentialFieldsRestriction": "No Restriction",
    "credentials": null,
    "credentialsVar": null,
    "description": "AWS file transfer operations v5.12",
    "desktopInteract": false,
    "elevateUser": false,
    "environment": [],
    "environmentVariablesFieldsRestriction": "No Restriction",
    "exitCodeOutput": null,
    "exitCodeProcessing": "Success Exitcode Range",
    "exitCodeProcessingFieldsRestriction": "No Restriction",
    "exitCodeText": null,
    "exitCodes": "0",
    "fields": [
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "list-buckets",
                    "sequence": 0,
                    "sysId": "1d277e6f69754ae8a9ec9aa577186254",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "list-objects",
                    "sequence": 1,
                    "sysId": "2a4531e6f67f421aa9b12a0d3f240d42",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "upload-file",
                    "sequence": 2,
                    "sysId": "44d9f95a194c480f871c1ee825bd9f47",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "download-file",
                    "sequence": 3,
                    "sysId": "7416f62f4c6345b7a369a4137ceb2f1a",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "delete-objects",
                    "sequence": 4,
                    "sysId": "173385584a3f4f98b43c7aace2b43164",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "delete-bucket",
                    "sequence": 5,
                    "sysId": "1995d83458db4653bb78353a31779749",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "create-bucket",
                    "sequence": 6,
                    "sysId": "657eba76037e45c8a094c5e570d33697",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "copy-object-to-bucket",
                    "sequence": 7,
                    "sysId": "986fcafa50d94a328e0b68f9a6d8803c",
                    "useFieldValueForLabel": true
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 3",
            "fieldType": "Choice",
            "fieldValue": "list-buckets",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Action",
            "name": "action",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 0,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "62c1cdb1d11e490dad509ee84141f2a7"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 3",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Bucket",
            "name": "object_store",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 1,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "upload-file,create-bucket,delete-bucket,delete-objects,download-file,list-objects,copy-object-to-bucket",
            "sysId": "e5392a9ca4914c53973eea01789d39ad"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 8",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Target Bucket",
            "name": "target_object_store",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 6,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "copy-object-to-bucket",
            "sysId": "494dbb63c6144f0aa94fb47856986ec8"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 6",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Sourcefile",
            "name": "sourcefile",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 7,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "upload-file",
            "sysId": "406609d8d3694442bdd959c4e1e7ea9e"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 9",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "target directory path e.g. C:\\tmp\\ or /home/ubuntu/download",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Target Directory",
            "name": "targetdir",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 8,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "download-file",
            "sysId": "281b2110afe64ce48b860891e0d57112"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 4",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "S3Key",
            "name": "object",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 10,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "delete-objects,download-file,copy-object-to-bucket,list-objects",
            "sysId": "c70e5bfdb2094c62977f150f5b904026"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "copy",
                    "sequence": 0,
                    "sysId": "4d98e50d1d8247449ce3d6707cebc6d8",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "move",
                    "sequence": 1,
                    "sysId": "1eea5ee9729f4f998928d03eb27cbf3b",
                    "useFieldValueForLabel": true
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 4",
            "fieldType": "Choice",
            "fieldValue": "copy",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Operation",
            "name": "operation",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 11,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "upload-file,download-file",
            "sysId": "d89031df92b34964b2fcf291841a09df"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 7",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "The prefix limits the results to only those keys that begin with the specified prefix",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Prefix",
            "name": "prefix",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 13,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "list-objects,upload-file",
            "sysId": "6e497847e62643af956d828c561cb787"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Boolean Field 2",
            "fieldType": "Boolean",
            "fieldValue": "false",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "list key details, keyname,LastModified timestamp, size",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Show Details",
            "name": "show_details",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 14,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "list-objects",
            "sysId": "624e4b2ce74f46c4a2aeb5d0997c20f8"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "True",
                    "fieldValueLabel": "Replace existing file",
                    "sequence": 0,
                    "sysId": "88777f644a194f7e956c323251f489d8",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "False",
                    "fieldValueLabel": "Do not overwrite existing file",
                    "sequence": 1,
                    "sysId": "eeb1340b879f4cd9bf019fb21d953e45",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "Timestamp",
                    "fieldValueLabel": "Timestamp",
                    "sequence": 2,
                    "sysId": "dfbc0224e0d54509a03e72992f655d29",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "Rename",
                    "fieldValueLabel": "Windows default behavior",
                    "sequence": 3,
                    "sysId": "5b0ca1f3d46e469a95f3b1c562416dd0",
                    "useFieldValueForLabel": false
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 5",
            "fieldType": "Choice",
            "fieldValue": "False",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Download Write Options",
            "name": "writeoptions_download",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 15,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "download-file",
            "sysId": "61ad7312f2624e0196bb63b01891a593"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "True",
                    "fieldValueLabel": "Replace existing Object",
                    "sequence": 0,
                    "sysId": "89bdd2a422e1466a91123a3576cc132d",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "False",
                    "fieldValueLabel": "Do not overwrite existing object",
                    "sequence": 1,
                    "sysId": "8e336102bba44671867784ba11a71f0b",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "Timestamp",
                    "fieldValueLabel": "Timestamp",
                    "sequence": 2,
                    "sysId": "646e21e98e5041dc832280f939974ebb",
                    "useFieldValueForLabel": false
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 6",
            "fieldType": "Choice",
            "fieldValue": "False",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Upload Write Options",
            "name": "writeoptions_upload",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 16,
            "showIfField": "Choice Field 3",
            "showIfFieldValue": "upload-file,copy-object-to-bucket",
            "sysId": "e5ead46d387e4685bfb1acc0573be60a"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Credential Field 4",
            "fieldType": "Credential",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "AWS_SECRET_ACCESS_KEY",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "AWS_SECRET_ACCESS_KEY",
            "name": "aws_secret_access_key",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": true,
            "sequence": 17,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "22d0100ff016486a812cb4de7014e89b"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Credential Field 3",
            "fieldType": "Credential",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "AWS_ACCESS_KEY_ID",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "AWS_ACCESS_KEY_ID",
            "name": "aws_access_key_id",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": true,
            "sequence": 18,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "dcd35cfc51ff4707b9e8e1dd4c5263ed"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 12",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "e.g. eu-central-1, us-east-2",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "AWS_DEFAULT_REGION",
            "name": "aws_default_region_name",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": true,
            "sequence": 21,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "82fd66b5b38f47efacf973df9c75ad23"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "1",
                    "fieldValueLabel": "Yes",
                    "sequence": 0,
                    "sysId": "b5910c1710c349ee80ad6f95f28878d5",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "0",
                    "fieldValueLabel": "No",
                    "sequence": 1,
                    "sysId": "c535b2b94a1c4b8f9bf85301064999c5",
                    "useFieldValueForLabel": false
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 1",
            "fieldType": "Choice",
            "fieldValue": "0",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "connect to s3 direct or via proxy server, if \"Yes\" is Proxy and Port field are mandatory",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Useproxy",
            "name": "useproxy",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 23,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "1f6712feefe442a886a2ec486df0bceb"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "http",
                    "sequence": 0,
                    "sysId": "a5d78323f0354df6abe10290690de020",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "https",
                    "sequence": 1,
                    "sysId": "cc9bf9a2915e4289aa1b602da48c6d6b",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "https_with_password",
                    "sequence": 2,
                    "sysId": "0b14e3d46dcf430eb85f1cd314dba1df",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "http_with_password",
                    "sequence": 3,
                    "sysId": "2f4e26669390494d9652128c9f65cfad",
                    "useFieldValueForLabel": true
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 2",
            "fieldType": "Choice",
            "fieldValue": "http",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "https or http proxy connection",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Proxy Type",
            "name": "proxy_type",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 24,
            "showIfField": "Choice Field 1",
            "showIfFieldValue": "1",
            "sysId": "54a9964fdc764d24baf88730d762894f"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 1",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "proxy server ip or hostname",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Proxy",
            "name": "proxy",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 25,
            "showIfField": "Choice Field 1",
            "showIfFieldValue": "1",
            "sysId": "09d748f806bd4633ac39c9a9e0a0a97f"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Credential Field 1",
            "fieldType": "Credential",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Proxycred",
            "name": "proxycred",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 26,
            "showIfField": "Choice Field 2",
            "showIfFieldValue": "http_with_password,https_with_password",
            "sysId": "03208e2704b542559f4e983db2744b5a"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 2",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "proxy server port",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Port",
            "name": "port",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 27,
            "showIfField": "Choice Field 1",
            "showIfFieldValue": "1",
            "sysId": "486897bdac6444589f3b18e838f5e2fe"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "no",
                    "fieldValueLabel": "No",
                    "sequence": 0,
                    "sysId": "88cef437f0664e8dab00dc4ea92c74f2",
                    "useFieldValueForLabel": false
                },
                {
                    "fieldValue": "yes",
                    "fieldValueLabel": "Yes",
                    "sequence": 1,
                    "sysId": "e8d46ff5e62840968d48713d3a546c46",
                    "useFieldValueForLabel": false
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 9",
            "fieldType": "Choice",
            "fieldValue": "no",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "AWS IAM RBCA - Role Based Access",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Role Based Access",
            "name": "rbca",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 28,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "df62c0ea44764a008504b8072db43e96"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "sts",
                    "sequence": 0,
                    "sysId": "b62038da7e7f4cdabf56f1c45566b869",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "s3",
                    "sequence": 1,
                    "sysId": "037aac29903049a9b0129b69b51af66e",
                    "useFieldValueForLabel": true
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 8",
            "fieldType": "Choice",
            "fieldValue": "sts",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Service Name",
            "name": "service_name",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 30,
            "showIfField": "Choice Field 9",
            "showIfFieldValue": "yes",
            "sysId": "996b28f30e9642e698d90d782708f66c"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 10",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": "resources are indentified in AWS by an Amazon Resource Name (ARN) - role arn is the ressource name for a role",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Role ARN",
            "name": "rolearn",
            "noSpaceIfHidden": true,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 31,
            "showIfField": "Choice Field 9",
            "showIfFieldValue": "yes",
            "sysId": "ec46f434be6d4aeebcaaa8f7065505f3"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [
                {
                    "fieldValue": "INFO",
                    "sequence": 0,
                    "sysId": "ff2ef1f432b64daca30c606d0b55a061",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "DEBUG",
                    "sequence": 1,
                    "sysId": "b08100662aad43f8ab94ef160ff198db",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "WARNING",
                    "sequence": 2,
                    "sysId": "77a0115d9a1c45f29ec5919174e8850f",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "ERROR",
                    "sequence": 3,
                    "sysId": "336d06e346d24dcd95260c939f3854a3",
                    "useFieldValueForLabel": true
                },
                {
                    "fieldValue": "CRITICAL",
                    "sequence": 4,
                    "sysId": "b0ac9b2cea6e406ca767cde8050aeeeb",
                    "useFieldValueForLabel": true
                }
            ],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Choice Field 7",
            "fieldType": "Choice",
            "fieldValue": "INFO",
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": true,
            "hint": null,
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Loglevel",
            "name": "loglevel",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 32,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "1a0efff9d732417d9146612aec0b57cb"
        },
        {
            "arrayNameTitle": null,
            "arrayValueTitle": null,
            "booleanNoValue": null,
            "booleanValueType": "true/false",
            "booleanYesValue": null,
            "choiceAllowEmpty": false,
            "choiceAllowMultiple": false,
            "choiceSortOption": "Sequence",
            "choices": [],
            "defaultListView": false,
            "fieldLength": null,
            "fieldMapping": "Text Field 11",
            "fieldType": "Text",
            "fieldValue": null,
            "formColumnSpan": 1,
            "formEndRow": false,
            "formStartRow": false,
            "hint": "e.g. MINIO: http://<>:9000",
            "intFieldMax": null,
            "intFieldMin": null,
            "label": "Endpoint URL",
            "name": "endpoint_url",
            "noSpaceIfHidden": false,
            "requireIfField": null,
            "requireIfFieldValue": null,
            "requireIfVisible": false,
            "required": false,
            "sequence": 33,
            "showIfField": null,
            "showIfFieldValue": null,
            "sysId": "4bdca6da59e941a89432500382c54fcd"
        }
    ],
    "name": "AWS-S3",
    "outputFailureOnly": false,
    "outputReturnFile": null,
    "outputReturnNline": "100",
    "outputReturnSline": "1",
    "outputReturnText": null,
    "outputReturnType": "OUTERR",
    "outputType": "STDOUT",
    "runtimeDir": null,
    "script": null,
    "scriptTypeWindows": ".uapy",
    "scriptUnix": "#!/opt/universal/python3.6/bin/python3\n###############################################################################\n#\n#    Name: s3_aws.py\n#\n#         Origins: Stonebranch\n#          Author: Abdullah Saglam, Nils Buer\n#            Date: 25-AUG-2020\n#\n#    Requires Universal Agent for Linux/Windows/...\n#\n#    Copyright (c) Stonebranch, 2020.  All rights reserved.\n#\n#    Purpose: Universal Task for Amazon S3 operations\n#\n#     Version History:\n#     0.9  Bryant Hardy 2017-11-05 Initial Version\n#     1.0  Nils Buer 2017-11-09    using SB Code standards\n#     2.0  Nils Buer 2018-04-04    logging and credentials\n#     3.0  A Saglam  2019-08-19    changes for Axa\n#     3.1  Nils Buer 2019-09-13    PWD print removed old function removed\n#     3.2  A Saglam  2020-04-29    merged changes for Axa De\n#     4.0  NBU,ASA   2020-08-25    merged all S3 tasks into one\n#     4.1  NBU,ASA   2020-09-04    bugfix\n#     4.2  NBU,ASA   2020-09-04    fix, client 4 list objects isstorage_resource\n#     4.3  NBU,ASA   2020-09-10    bugfix, windows paths made raw string\n#     4.4  NBU       2020-09-11    list bucket content with prefix support\n#     4.5  ASA       2020-09-16    download overwrite protection\n#                                  upload prefix support\n#     4.6  ASA       2020-09-21    bugfix\n#     4.7  ASA       2020-09-21    bugfix\n#     4.8  ASA       2020-09-24    copy from bucket to bucket\n#     4.9  ASA       2020-09-29    / bug with empty prefix, error with 0 files\n#     4.10 ASA       2020-10-01    all overwrite options are supported\n#     4.11 ASA       2020-10-02    bugfix\n#     4.12 ASA       2020-10-02    download dir\n#     4.13 ASA       2020-10-05    delete with pattern added,\n#                                  overwrite info updated\n#     4.14 ASA       2020-10-05    bugfix\n#     4.15 ASA       2020-10-08    bugfix\n#     4.16 ASA       2020-10-08    bugfix\n#     4.17 NBU       2020-10-09    endpoint_url added for MINIO support\n#     5.00 NBU,ASA   2020-10-20    changes for common naming for ft tasks\n#     5.01 ASA       2020-10-21    bugfix\n#     5.02 ASA       2020-10-21    bugfix\n#     5.03 NBU,ASA   2020-10-26    rbac added\n#     5.04 NBU,ASA   2020-10-26    sqs region added\n#     5.05 NBU,ASA   2020-11-25    region changed from credential to Text field\n#     5.06 NBU,ASA   2020-12-02    proxy settings updated\n#     5.07 NBU,ASA   2020-12-02    proxy settings updated\n#     5.08 NBU,ASA   2020-12-02    proxy settings updated\n#     5.09 NBU,ASA   2020-12-02    proxy settings updated\n#     5.10 NBU,ASA   2021-02-11    exception handling create bucket\n#     5.11 NBU,ASA   2021-02-16    bugfix\n#     5.12 NBU,ASA   2021-02-16    bugfix\n###############################################################################\n\nimport datetime\nimport time\nimport boto3\nimport botocore\nimport logging\nimport os\nfrom botocore import exceptions\nfrom botocore.config import Config\nimport fnmatch\nimport sys\n\ngl_version = \"5.12\"\ngl_variable_prefix = \"var\"\ngl_action = \"${ops_var_action}\"\n\nlogging.basicConfig(level=\"${ops_var_loglevel}\",\n                    format=' %(asctime)s - %(levelname)s - %(message)s')\n\n\ndef main():\n    print_variables()\n    endpoint_url = None if not \"${ops_var_endpoint_url}\".strip() else \"${ops_var_endpoint_url}\".strip()\n    role_arn = None if not \"${ops_var_rolearn}\".strip() else \"${ops_var_rolearn}\".strip()\n    sb_con = SbAws(endpoint_url,\n                   \"${_credentialPwd('${ops_var_aws_access_key_id}')}\",\n                   \"${_credentialPwd('${ops_var_aws_secret_access_key}')}\",\n                   role_arn,\n                   \"${ops_var_aws_default_region_name}\",\n                   \"${ops_var_useproxy}\",\n                   \"${ops_var_proxy_type}\",\n                   \"${_credentialUser('${ops_var_proxycred}')}\",\n                   \"${_credentialPwd('${ops_var_proxycred}')}\",\n                   \"${ops_var_proxy}\",\n                   \"${ops_var_port}\")\n\n    if gl_action == \"list-buckets\":\n        sb_con.list_object_stores()\n        pass\n    elif gl_action == \"list-objects\":\n        sb_con.list_object_store_content(\"${ops_var_object_store}\",\n                                         \"${ops_var_prefix}\",\n                                         \"${ops_var_object}\",\n                                         \"${ops_var_show_details}\")\n        pass\n    elif gl_action == \"upload-file\":\n        sb_con.copy_all_files_to_object_store(r\"${ops_var_sourcefile}\",\n                                              \"${ops_var_object_store}\",\n                                              \"${ops_var_prefix}\",\n                                              \"${ops_var_writeoptions_upload}\",\n                                              \"${ops_var_operation}\")\n        pass\n    elif gl_action == \"download-file\":\n        sb_con.download_all_files_from_object_store(\n            r\"${ops_var_targetdir} \".strip(),\n            \"${ops_var_object_store}\",\n            \"${ops_var_object}\",\n            \"${ops_var_writeoptions_download}\",\n            \"${ops_var_operation}\")\n        pass\n    elif gl_action == \"delete-objects\":\n        if \"${ops_var_object}\".strip() is \"*\":\n            logging.error(\n                \"Delete ('*') not allowed, please put a more specific pattern\")\n            exit(1)\n        sb_con.delete_all_objects_from_object_store(\n            \"${ops_var_object_store}\",\n            \"${ops_var_object}\")\n        pass\n    elif gl_action == \"delete-bucket\":\n        sb_con.delete_object_store(\"${ops_var_object_store}\")\n        pass\n    elif gl_action == \"create-bucket\":\n        sb_con.create_object_store(\"${ops_var_object_store}\")\n        pass\n    elif gl_action == \"copy-object-to-bucket\":\n        sb_con.copy_all_objects_to_object_store(r\"${ops_var_object}\",\n                                                \"${ops_var_object_store}\",\n                                                \"${ops_var_target_object_store}\",\n                                                \"${ops_var_writeoptions_upload}\",\n                                                \"${ops_var_operation}\")\n        pass\n\n\ndef print_variables():\n    logging.info(\"Python version <<< \" + sys.version + \" >>>\")\n    logging.info(\"Executing task version \" + gl_version + \" with the following \"\n                                                          \"parameters\")\n    print_defined_variables(gl_variable_prefix)\n\n\ndef print_defined_variables(variable_prefix):\n    all_variables = r\"\"\"${_scope}\"\"\"\n    separate_variables = [variable for variable in all_variables.split(', ') if\n                          \"ops_\" + variable_prefix in variable]\n    logging.info(str(separate_variables).replace(\", \", \",\\n\"))\n\n\nclass SbAws:\n    \"\"\"Stonebranch Amazon Web Services Class for python\n\n    This class is written for file operations\n    to and from AWS\n\n    Attributes:\n        _storage_client: keeps the resource identifier\n        _library_version: keeps the class library version\n        _region_name: region name\n    \"\"\"\n\n    def __init__(self,\n                 endpoint_url,\n                 aws_access_key_id,\n                 aws_secret_access_key,\n                 role_arn,\n                 region_name,\n                 use_proxy=\"0\",\n                 proxy_type=\"http\",\n                 proxy_user=None,\n                 proxy_passwd=None,\n                 proxy_host=None,\n                 proxy_port=None):\n        \"\"\"Initiates the class instance\n\n        Initiates the class instance with with the given parameters\n\n        Args:\n            endpoint_url : MINIO endpoint\n            aws_access_key_id: Aws access key id\n            aws_secret_access_key: Aws access key\n            role_arn: role arn for rbac\n            region_name: Region name\n            use_proxy: proxy use flag, 0 or 1\n            proxy_type: proxy type, http or https\n            proxy_user: proxy user information\n            proxy_passwd: proxy password information\n            proxy_host: proxy host information\n            proxy_port: proxy port information\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        self._storage_client = None\n        self._storage_resource = None\n        self._storage_session = None\n        self._library_version = \"1.1\"\n        logging.info(\n            \"AWS SB library version \" + self._library_version)\n        self._region_name = region_name\n        self.connect_aws(endpoint_url,\n                         aws_access_key_id,\n                         aws_secret_access_key,\n                         role_arn,\n                         region_name,\n                         use_proxy,\n                         proxy_type,\n                         proxy_user,\n                         proxy_passwd,\n                         proxy_host,\n                         proxy_port)\n\n    def __del__(self):\n        \"\"\"Destructor of the class instance\"\"\"\n        self._storage_client = None\n        self._storage_resource = None\n        self._storage_session = None\n\n    def connect_aws(self, endpoint_url,\n                    aws_access_key_id,\n                    aws_secret_access_key,\n                    role_arn,\n                    region_name,\n                    use_proxy=\"0\",\n                    proxy_type=\"http\",\n                    proxy_user=None,\n                    proxy_passwd=None,\n                    proxy_host=None,\n                    proxy_port=None):\n        \"\"\"Connects to cloud.\n\n        Connects to the cloud with or without proxy\n        Assigns the resource id to _storage_client\n\n        Args:\n            endpoint_url: end point to MINIO\n            aws_access_key_id: Aws access key id\n            aws_secret_access_key: Aws access key\n            role_arn: role arn for rbac\n            region_name: Region name\n            use_proxy: proxy use flag, 0 or 1\n            proxy_type: proxy type, http or https\n            proxy_user: proxy user information\n            proxy_passwd: proxy password information\n            proxy_host: proxy host information\n            proxy_port: proxy port information\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        logging.debug('Establishing connection')\n        proxy_config_str = None\n        proxy_string = \"\"\n        use_proxy_string = \"\"\n        if use_proxy in \"Yes,true,True,1\":\n            # connection via Proxy\n            logging.info('S3 Connection via Proxy: %s:%s' % (\n                proxy_host, proxy_port))\n            if proxy_type == \"https_with_password\":\n                proxy_string = \"https://%s:%s@%s:%s\" % (\n                    proxy_user, proxy_passwd, proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'https': '%s' % proxy_string}\n            elif proxy_type == \"https\":\n                proxy_string = \"https://%s:%s\" % (\n                    proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'https': '%s' % proxy_string}\n            elif proxy_type == \"http_with_password\":\n                proxy_string = \"http://%s:%s@%s:%s\" % (\n                    proxy_user, proxy_passwd, proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'http': '%s' % proxy_string}\n            else:\n                proxy_string = \"http://%s:%s\" % (\n                    proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'http': '%s' % proxy_string}\n        else:\n            # connection without Proxy\n            # Create a S3 client, provide the AWS credentials, provide proxy\n            logging.info('Direct S3 Connection without Proxy')\n        if proxy_string:\n            proxy_config_str = Config(proxies=use_proxy_string)\n            logging.info('Proxy Config: %s' % str(use_proxy_string))\n        if role_arn:\n            logging.info('Authentication RBAC')\n            sts_client = boto3.client('sts',\n                                      aws_access_key_id=aws_access_key_id,\n                                      aws_secret_access_key=aws_secret_access_key,\n                                      config=proxy_config_str)\n            assumed_role_object = sts_client.assume_role(\n                RoleArn=role_arn,\n                RoleSessionName=\"AssumeRoleSession1\"\n            )\n            credentials = assumed_role_object['Credentials']\n            s3client = boto3.client(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=f['AccessKeyId'],\n                aws_secret_access_key=credentials['SecretAccessKey'],\n                aws_session_token=credentials['SessionToken'],\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_client = s3client\n            s3resource = boto3.resource(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=credentials['AccessKeyId'],\n                aws_secret_access_key=credentials['SecretAccessKey'],\n                aws_session_token=credentials['SessionToken'],\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_resource = s3resource\n        else:\n            logging.info('Authentication Access Key')\n            s3client = boto3.client(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=aws_access_key_id,\n                aws_secret_access_key=aws_secret_access_key,\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_client = s3client\n            s3resource = boto3.resource(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=aws_access_key_id,\n                aws_secret_access_key=aws_secret_access_key,\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_resource = s3resource\n\n    def create_object_store(self, bucket_name):\n        \"\"\"Creates a bucket in S3.\n\n        Creates a bucket in S3 if it does not exist\n\n        Args:\n            bucket_name: bucket name to be created\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.meta.client.head_bucket(Bucket='%s' %\n                                                                  bucket_name)\n            logging.error('bucket: %s already exist' % bucket_name)\n            exit(1)\n        except botocore.exceptions.ClientError as e:\n            # If a client error is thrown, then check that it was a 404 error.\n            # If was a 404 error, then bucket does not exist, will be created\n            error_code = int(e.response['Error']['Code'])\n            if error_code == 403:\n                logging.error(\n                    'bucket: %s is a Private Bucket. Forbidden Access!' %\n                    bucket_name)\n                exit(1)\n            elif error_code == 404:\n                logging.info('bucket: %s does not exist and will be created.' %\n                             bucket_name)\n                try:\n                    response = self._storage_resource.create_bucket(\n                        Bucket='%s' % bucket_name,\n                        CreateBucketConfiguration={\n                            'LocationConstraint': self._region_name})\n                    logging.info('bucket: %s created. response: %s' %\n                                 (bucket_name, response))\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n\n    def delete_object_store(self, bucket_name):\n        \"\"\"Deletes a bucket in S3.\n\n        Deletes a bucket in S3 if it exists and is empty\n\n        Args:\n            bucket_name: bucket name to be deleted\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_client.delete_bucket(Bucket='%s' % bucket_name)\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchBucket':\n                logging.info(' bucket %s does not exist' % bucket_name)\n                exit(1)\n            elif e.response['Error']['Code'] == 'BucketNotEmpty':\n                logging.info(' bucket %s is not empty' % bucket_name)\n                exit(1)\n            else:\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info(' bucket %s deleted' % bucket_name)\n\n    def list_object_stores(self):\n        \"\"\"Lists all the buckets available.\n\n        Lists all the buckets available\n\n        Args:\n            -\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        for bucket in self._storage_resource.buckets.all():\n            logging.info(bucket.name)\n\n    def __check_file_exist_in_object_store(self, key, bucket_name):\n        \"\"\"Checks for file in S3 bucket.\n\n        Checks if file is in S3 bucket\n\n        Args:\n            bucket_name: bucket name\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.Object('%s' % bucket_name, '%s' % key).load()\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                logging.debug('Key: %s does not exist' % key)\n                return False\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info('Key: %s already exist' % key)\n            return True\n\n    def copy_all_files_to_object_store(self, source_file,\n                                       bucket_name,\n                                       prefix,\n                                       overwrite=\"true\",\n                                       operation=\"copy\"):\n        \"\"\"Copies all files to S3.\n\n        Copies all files matching the pattern to S3\n\n        Args:\n            source_file: source file with unix pattern\n            bucket_name: bucket name\n            prefix: prefix to be added to key\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        dir_name, filename = os.path.split(os.path.abspath(source_file))\n        files = fnmatch.filter(os.listdir(dir_name), filename)\n        if not files:\n            logging.error('No file(s) found! %s' % filename)\n            exit(1)\n        logging.info(\"files matching:\" + str(files))\n        transfer_success = True\n        stripped_prefix = prefix.lstrip(r\" /\\ \").strip()\n        for file in files:\n            full_path = dir_name + \"/\" + file\n            if stripped_prefix:\n                file_with_prefix = stripped_prefix + \"/\" + file\n            else:\n                file_with_prefix = file\n            if self.__copy_file_to_object_store_param(full_path,\n                                                      bucket_name,\n                                                      file_with_prefix,\n                                                      overwrite) is True:\n                if operation == \"move\":\n                    self.delete_file_on_disk(full_path)\n            else:\n                transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n\n    def __copy_file_to_object_store_param(self,\n                                          full_path,\n                                          bucket_name,\n                                          target_file_name,\n                                          overwrite):\n        \"\"\"Copies file to S3 target bucket.\n\n        Copies source file in parameter to S3 target bucket\n\n        Args:\n            full_path: source file path\n            bucket_name: bucket name\n            target_file_name: target file name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        if not target_file_name.strip():\n            dir_name, file_name = os.path.split(os.path.abspath(full_path))\n        else:\n            file_name = target_file_name\n\n        if self.__check_file_exist_in_object_store(file_name, bucket_name):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info(\n                    'Key: %s exists and '\n                    'will be overwritten due to overwrite flag set to %s' %\n                    (file_name, overwrite))\n                try:\n                    self._storage_client.upload_file('%s' % full_path,\n                                                     bucket_name,\n                                                     file_name)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'Key: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (file_name, file_name + timestamp))\n                try:\n                    self._storage_client.upload_file('%s' % full_path,\n                                                     bucket_name,\n                                                     file_name + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % file_name)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                self._storage_client.upload_file('%s' %\n                                                 full_path,\n                                                 bucket_name,\n                                                 file_name)\n            except botocore.exceptions.ClientError as e:\n                logging.error(e)\n                exit(1)\n            logging.info(\n                'Finished uploading file: %s, to bucket: %s as key: %s' %\n                (full_path, bucket_name, file_name))\n        return True\n\n    @staticmethod\n    def delete_file_on_disk(file_name):\n        \"\"\"Delete a file that exists on disk.\n\n        Deletes a file that exists on local disk\n\n        Args:\n            file_name: file name to be checked\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            os.remove(file_name)\n        except OSError as e:  # operation failed, report it back to the user\n            logging.error(\"Error: %s - %s.\" % (e.filename, e.strerror))\n            return False\n        else:\n            logging.info(\"File %s deleted successfully\" % file_name)\n            return True\n\n    def download_all_files_from_object_store(self,\n                                             in_target_directory,\n                                             bucket_name,\n                                             key_file,\n                                             overwrite=\"true\",\n                                             operation=\"copy\"):\n        \"\"\"Downloads all files from S3.\n\n        Downloads all files matching the pattern from S3\n\n        Args:\n            in_target_directory: target file with path and with unix pattern\n            bucket_name: bucket name\n            key_file: file name\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        if not self.check_directory_exist_writeable_disk(in_target_directory):\n            exit(1)\n        files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n        transfer_success = True\n        # download file into current directory\n        downloaded = False\n        for fb_object in files_bucket.objects.all():\n            # split object.key into path and file name\n            path, filename = os.path.split(fb_object.key)\n            if fnmatch.fnmatch(fb_object.key, key_file):\n                logging.debug(fb_object.key)\n                if self.__download_file_from_object_store_param(bucket_name,\n                                                                fb_object.key,\n                                                                in_target_directory,\n                                                                filename,\n                                                                overwrite) is True:\n                    downloaded = True\n                    if operation == \"move\":\n                        self.__delete_object_from_object_store(bucket_name,\n                                                       fb_object.key)\n                else:\n                    transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n        if downloaded is False:\n            logging.error('No key(s) found! %s' % key_file)\n            exit(1)\n\n    @staticmethod\n    def check_file_exists_disk(file_name):\n        \"\"\"Checks if a file exists on disk.\n\n        Checks if a file exists on local disk\n\n        Args:\n            file_name: file name to be checked\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        if os.path.isfile(file_name):\n            logging.debug('File exists:' + file_name)\n            return True\n        else:\n            logging.debug('File does not exist: ' + file_name)\n            return False\n\n    @staticmethod\n    def check_directory_exist_writeable_disk(directory_name):\n        \"\"\"Checks if a directory exists and is writeable on disk.\n\n        Checks if a directory exists and is writeable on local disk\n\n        Args:\n            directory_name: directory name to be checked\n\n        Returns:\n            True if the directory exists and is writeable\n            False if the directory does not exist or not is writeable\n\n        Raises:\n            -\n        \"\"\"\n        if not os.path.exists(directory_name):\n            logging.error('Directory does not exist: ' + directory_name)\n            return False\n        elif os.access(directory_name, os.W_OK):\n            logging.debug('Directory is writeable: ' + directory_name)\n            return True\n        else:\n            logging.error('Directory is not writeable: ' + directory_name)\n            return False\n\n    def __download_file_from_object_store_param(self,\n                                                bucket_name,\n                                                key,\n                                                dir_name,\n                                                file,\n                                                overwrite):\n        \"\"\"Downloads file from S3.\n\n        Downloads file from S3 to dir_name/file\n\n        Args:\n            bucket_name: bucket name\n            key: source file name\n            dir_name: target directory path\n            file: target file name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                adds an index \" (i)\" up to 16 like windows\n                    if the value is \"Rename\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        target_full_path = os.path.join(dir_name, file)\n        # Download file from S3 source bucket\n        if self.check_file_exists_disk(target_full_path):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info('File: %s exists and '\n                             'will be overwritten due to '\n                             'overwrite flag set to %s' %\n                             (target_full_path, overwrite))\n                try:\n                    logging.info('Start Downloading File: %s ,'\n                                 'from bucket: %s to file: %s' %\n                                 (key, bucket_name, target_full_path))\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % target_full_path)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error('The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n                else:\n                    logging.info('Downloading File: %s ,'\n                                 'from bucket: %s to file: %s finished' %\n                                 (key, bucket_name, target_full_path))\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'File: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (target_full_path, target_full_path + timestamp))\n                try:\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % target_full_path + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error('The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n                else:\n                    logging.info(\n                        'Downloading File: %s ,from bucket: %s '\n                        'to file: %s finished' %\n                        (key, bucket_name, target_full_path))\n            elif overwrite in \"Rename\":\n                file_name, file_extension = os.path.splitext(target_full_path)\n                new_target_file_name = \"\"\n                for index in range(1, 17):\n                    new_file_name = file_name + \" (%d)%s\" % (\n                        index, file_extension)\n                    logging.debug(\"new file: \" + new_file_name)\n                    if os.path.isfile(new_file_name):\n                        logging.debug(new_file_name + \" already exists\")\n                    else:\n                        new_target_file_name = new_file_name\n                        logging.info(\n                            'File: %s exists and '\n                            'new one will be renamed and written as %s' %\n                            (target_full_path, new_file_name))\n                        break\n                if not new_target_file_name.strip():\n                    logging.error(\n                        \"Max rename index limit (%d) reached, exiting\" % index)\n                    return False\n                try:\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % new_target_file_name)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error(\n                            'The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % target_full_path)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                logging.info(\n                    'Start Downloading File: %s ,'\n                    'from bucket: %s to file: %s' %\n                    (key, bucket_name, target_full_path))\n                self._storage_resource.Bucket(\n                    '%s' % bucket_name).download_file('%s' % key,\n                                                      '%s' % target_full_path)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    logging.error('The object does not exists: %s' % key)\n                    exit(404)\n                else:\n                    raise\n            except Exception as unknown_exception:\n                logging.error(unknown_exception)\n                exit(1)\n            else:\n                logging.info(\n                    'Downloading File: %s ,from bucket: %s to file: '\n                    '%s finished' %\n                    (key, bucket_name, target_full_path))\n        return True\n\n    def delete_all_objects_from_object_store(self,\n                                             bucket_name,\n                                             key_file):\n        \"\"\"Deletes all files from S3.\n\n        Deletes all files matching the pattern from S3\n\n        Args:\n            bucket_name: bucket name\n            key_file: file name\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n\n        files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n        matched_object = False\n        for fb_object in files_bucket.objects.all():\n            logging.debug(fb_object.key)\n            # split object.key into path and file name\n            if fnmatch.fnmatch(fb_object.key, key_file):\n                matched_object = True\n                self.__delete_object_from_object_store(bucket_name, fb_object.key)\n        if not matched_object:\n            pattern_chars = [\"*\", \"?\", \"[\", \"]\"]\n            if any(pattern_char in key_file for pattern_char in pattern_chars):\n                logging.error(\n                    \"delete: cannot remove '%s': No matching keys found\" % key_file)\n            else:\n                logging.error(\n                    \"delete: cannot remove '%s': No such key found\" % key_file)\n            exit(1)\n\n    def __delete_object_from_object_store(self, bucket_name, key):\n        \"\"\"Deletes file from S3.\n\n        Deletes key from S3 bucket\n\n        Args:\n            bucket_name: bucket name\n            key: source file name\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.Object('%s' % bucket_name, '%s' % key).get()\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchKey':\n                logging.error(' The object: %s does not exists' % key)\n                exit(403)\n            else:\n                logging.info('############################')\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info(': Key deleted: %s, from Bucket: %s' %\n                         (key, bucket_name))\n            self._storage_resource.Object('%s' % bucket_name,\n                                          '%s' % key).delete()\n\n    def list_object_store_content(self, bucket_name, prefix, s3_key,\n                                  show_details):\n        \"\"\"Lists the content of the bucket.\n\n        Lists the content of the bucket incl. prefix for further selection.\n        The prefix limits the results to only those keys that begin with the specified prefix\n\n        Args:\n            bucket_name: bucket name\n            prefix: prefix to limit result set\n            s3_key: s3 key or pattern to match and list the keys\n            show_details: list key, LastModified timestamp, size\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        # ## List the content of the bucket\n        my_bucket = self._storage_resource.Bucket(bucket_name)\n        stripped_prefix = prefix.lstrip(r\" /\\ \").strip()\n        stripped_key = s3_key.strip()\n        if not stripped_key:\n            stripped_key = \"*\"\n        if stripped_prefix:\n            key_with_prefix = stripped_prefix + \"/\" + stripped_key\n        else:\n            key_with_prefix = stripped_key\n        logging.debug(\"key_with_prefix: \" + key_with_prefix)\n        for s3_file in my_bucket.objects.all():\n            if key_with_prefix:\n                if fnmatch.fnmatch(s3_file.key, key_with_prefix):\n                    if show_details == \"true\":\n                        logging.info(\n                            f\"{s3_file.key}\\t {s3_file.last_modified}\\t {s3_file.size}\")\n                    else:\n                        logging.info(s3_file.key)\n            else:\n                logging.info(s3_file.key)\n\n    def check_file_on_object_store(self, bucket_name, s3key):\n        # check for file in S3 bucket\n        try:\n            self._storage_resource.Object(bucket_name, s3key).load()\n        except Exception as e:\n            if e.response['Error']['Code'] == \"404\":\n                logging.error('Object: %s not found in bucket: %s' % (\n                    s3key, bucket_name))\n                exit(1)\n            else:\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info('Object: %s found in bucket: %s' % (\n                s3key, bucket_name))\n\n    def check_file_on_object_store_new(self, bucket_name, s3key, interval=\"0\"):\n        \"\"\"Checks if file exist in S3 bucket.\n\n        Monitoring function that checks the file in S3 bucket\n        Sleeps with the given interval time\n\n        Args:\n            bucket_name: bucket name\n            s3key: file name unix pattern to expect\n            interval: sleeps in a loop with this interval\n                does not loop if the interval is \"0\"\n\n        Returns:\n            True whenever a file is found if the interval is \"1\"\n\n        Raises:\n            -\n        \"\"\"\n        files_bucket = None\n        found = False  # allow for at least one iteration\n        while not found:\n            try:\n                files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    found = False\n                    if interval == \"0\":\n                        logging.error('Object: %s not found in bucket: %s' % (\n                            s3key, bucket_name))\n                        exit(1)\n                    else:\n                        time.sleep(float(interval))\n                else:\n                    raise\n            except Exception as unknown_exception:\n                logging.error(unknown_exception)\n                exit(1)\n            else:\n                # download file into current directory\n                for fb_object in files_bucket.objects.all():\n                    # split object.key into path and file name\n                    path, filename = os.path.split(fb_object.key)\n                    if fnmatch.fnmatch(filename, s3key):\n                        logging.info('Object: %s found in bucket: %s' %\n                                     (filename, bucket_name))\n                        logging.info('LAUNCHTASK for %s in bucket: %s' %\n                                     (filename, bucket_name))\n                        found = True\n\n    def copy_all_objects_to_object_store(self,\n                                         source_object_name,\n                                         bucket_name,\n                                         target_bucket_name,\n                                         overwrite=\"true\",\n                                         operation=\"copy\"):\n        \"\"\"Copies all objects from a bucket to another.\n\n        Copies all objects matching the pattern to another bucket\n\n        Args:\n            source_object_name: source object name\n            bucket_name: bucket name\n            target_bucket_name: target bucket name\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        my_bucket = self._storage_resource.Bucket(bucket_name)\n        for s3_file in my_bucket.objects.all():\n            logging.info(s3_file.key)\n        all_key_objects = my_bucket.objects.all()\n        all_keys = [s3_key.key for s3_key in all_key_objects]\n        all_matching_keys = fnmatch.filter(all_keys, source_object_name)\n        if not all_matching_keys:\n            logging.error('No key(s) found! %s' % source_object_name)\n            exit(1)\n        logging.info(\"keys matching:\" + str(all_matching_keys))\n        transfer_success = True\n        for matching_key in all_matching_keys:\n            logging.info(\"copying key: \" + str(matching_key))\n            if self.__copy_object_to_object_store_param(matching_key,\n                                                        bucket_name,\n                                                        target_bucket_name,\n                                                        overwrite) is True:\n                if operation == \"move\":\n                    logging.warning(\"move not supported!\")\n                    pass\n            else:\n                transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n\n    def __copy_object_to_object_store_param(self,\n                                            source_object_name,\n                                            bucket_name,\n                                            target_bucket_name,\n                                            overwrite):\n        \"\"\"Copies object from bucket to S3 target bucket.\n\n        Copies source file in parameter to S3 target bucket\n\n        Args:\n            source_object_name: source object name\n            bucket_name: bucket name\n            target_bucket_name: target bucket name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n\n        copy_source = {\n            'Bucket': bucket_name,\n            'Key': source_object_name\n        }\n        target_bucket = self._storage_resource.Bucket(target_bucket_name)\n        if self.__check_file_exist_in_object_store(source_object_name,\n                                                   target_bucket_name):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info(\n                    'Key: %s exists and '\n                    'will be overwritten due to overwrite flag set to %s' %\n                    (source_object_name, overwrite))\n                try:\n                    target_bucket.copy(copy_source, source_object_name)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'Key: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (source_object_name, source_object_name + timestamp))\n                try:\n                    target_bucket.copy(copy_source,\n                                       source_object_name + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % source_object_name)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                target_bucket.copy(copy_source, source_object_name)\n            except botocore.exceptions.ClientError as e:\n                logging.error(e)\n                exit(1)\n            logging.info(\n                'Finished copying key: %s, to bucket: %s' %\n                (source_object_name, target_bucket_name))\n        return True\n\n\nif __name__ == '__main__':\n    main()\n",
    "scriptWindows": "#!/opt/universal/python3.6/bin/python3\n###############################################################################\n#\n#    Name: s3_aws.py\n#\n#         Origins: Stonebranch\n#          Author: Abdullah Saglam, Nils Buer\n#            Date: 25-AUG-2020\n#\n#    Requires Universal Agent for Linux/Windows/...\n#\n#    Copyright (c) Stonebranch, 2020.  All rights reserved.\n#\n#    Purpose: Universal Task for Amazon S3 operations\n#\n#     Version History:\n#     0.9  Bryant Hardy 2017-11-05 Initial Version\n#     1.0  Nils Buer 2017-11-09    using SB Code standards\n#     2.0  Nils Buer 2018-04-04    logging and credentials\n#     3.0  A Saglam  2019-08-19    changes for Axa\n#     3.1  Nils Buer 2019-09-13    PWD print removed old function removed\n#     3.2  A Saglam  2020-04-29    merged changes for Axa De\n#     4.0  NBU,ASA   2020-08-25    merged all S3 tasks into one\n#     4.1  NBU,ASA   2020-09-04    bugfix\n#     4.2  NBU,ASA   2020-09-04    fix, client 4 list objects isstorage_resource\n#     4.3  NBU,ASA   2020-09-10    bugfix, windows paths made raw string\n#     4.4  NBU       2020-09-11    list bucket content with prefix support\n#     4.5  ASA       2020-09-16    download overwrite protection\n#                                  upload prefix support\n#     4.6  ASA       2020-09-21    bugfix\n#     4.7  ASA       2020-09-21    bugfix\n#     4.8  ASA       2020-09-24    copy from bucket to bucket\n#     4.9  ASA       2020-09-29    / bug with empty prefix, error with 0 files\n#     4.10 ASA       2020-10-01    all overwrite options are supported\n#     4.11 ASA       2020-10-02    bugfix\n#     4.12 ASA       2020-10-02    download dir\n#     4.13 ASA       2020-10-05    delete with pattern added,\n#                                  overwrite info updated\n#     4.14 ASA       2020-10-05    bugfix\n#     4.15 ASA       2020-10-08    bugfix\n#     4.16 ASA       2020-10-08    bugfix\n#     4.17 NBU       2020-10-09    endpoint_url added for MINIO support\n#     5.00 NBU,ASA   2020-10-20    changes for common naming for ft tasks\n#     5.01 ASA       2020-10-21    bugfix\n#     5.02 ASA       2020-10-21    bugfix\n#     5.03 NBU,ASA   2020-10-26    rbac added\n#     5.04 NBU,ASA   2020-10-26    sqs region added\n#     5.05 NBU,ASA   2020-11-25    region changed from credential to Text field\n#     5.06 NBU,ASA   2020-12-02    proxy settings updated\n#     5.07 NBU,ASA   2020-12-02    proxy settings updated\n#     5.08 NBU,ASA   2020-12-02    proxy settings updated\n#     5.09 NBU,ASA   2020-12-02    proxy settings updated\n#     5.10 NBU,ASA   2021-02-11    exception handling create bucket\n#     5.11 NBU,ASA   2021-02-16    bugfix\n#     5.12 NBU,ASA   2021-02-16    bugfix\n###############################################################################\n\nimport datetime\nimport time\nimport boto3\nimport botocore\nimport logging\nimport os\nfrom botocore import exceptions\nfrom botocore.config import Config\nimport fnmatch\nimport sys\n\ngl_version = \"5.12\"\ngl_variable_prefix = \"var\"\ngl_action = \"${ops_var_action}\"\n\nlogging.basicConfig(level=\"${ops_var_loglevel}\",\n                    format=' %(asctime)s - %(levelname)s - %(message)s')\n\n\ndef main():\n    print_variables()\n    endpoint_url = None if not \"${ops_var_endpoint_url}\".strip() else \"${ops_var_endpoint_url}\".strip()\n    role_arn = None if not \"${ops_var_rolearn}\".strip() else \"${ops_var_rolearn}\".strip()\n    sb_con = SbAws(endpoint_url,\n                   \"${_credentialPwd('${ops_var_aws_access_key_id}')}\",\n                   \"${_credentialPwd('${ops_var_aws_secret_access_key}')}\",\n                   role_arn,\n                   \"${ops_var_aws_default_region_name}\",\n                   \"${ops_var_useproxy}\",\n                   \"${ops_var_proxy_type}\",\n                   \"${_credentialUser('${ops_var_proxycred}')}\",\n                   \"${_credentialPwd('${ops_var_proxycred}')}\",\n                   \"${ops_var_proxy}\",\n                   \"${ops_var_port}\")\n\n    if gl_action == \"list-buckets\":\n        sb_con.list_object_stores()\n        pass\n    elif gl_action == \"list-objects\":\n        sb_con.list_object_store_content(\"${ops_var_object_store}\",\n                                         \"${ops_var_prefix}\",\n                                         \"${ops_var_object}\",\n                                         \"${ops_var_show_details}\")\n        pass\n    elif gl_action == \"upload-file\":\n        sb_con.copy_all_files_to_object_store(r\"${ops_var_sourcefile}\",\n                                              \"${ops_var_object_store}\",\n                                              \"${ops_var_prefix}\",\n                                              \"${ops_var_writeoptions_upload}\",\n                                              \"${ops_var_operation}\")\n        pass\n    elif gl_action == \"download-file\":\n        sb_con.download_all_files_from_object_store(\n            r\"${ops_var_targetdir} \".strip(),\n            \"${ops_var_object_store}\",\n            \"${ops_var_object}\",\n            \"${ops_var_writeoptions_download}\",\n            \"${ops_var_operation}\")\n        pass\n    elif gl_action == \"delete-objects\":\n        if \"${ops_var_object}\".strip() is \"*\":\n            logging.error(\n                \"Delete ('*') not allowed, please put a more specific pattern\")\n            exit(1)\n        sb_con.delete_all_objects_from_object_store(\n            \"${ops_var_object_store}\",\n            \"${ops_var_object}\")\n        pass\n    elif gl_action == \"delete-bucket\":\n        sb_con.delete_object_store(\"${ops_var_object_store}\")\n        pass\n    elif gl_action == \"create-bucket\":\n        sb_con.create_object_store(\"${ops_var_object_store}\")\n        pass\n    elif gl_action == \"copy-object-to-bucket\":\n        sb_con.copy_all_objects_to_object_store(r\"${ops_var_object}\",\n                                                \"${ops_var_object_store}\",\n                                                \"${ops_var_target_object_store}\",\n                                                \"${ops_var_writeoptions_upload}\",\n                                                \"${ops_var_operation}\")\n        pass\n\n\ndef print_variables():\n    logging.info(\"Python version <<< \" + sys.version + \" >>>\")\n    logging.info(\"Executing task version \" + gl_version + \" with the following \"\n                                                          \"parameters\")\n    print_defined_variables(gl_variable_prefix)\n\n\ndef print_defined_variables(variable_prefix):\n    all_variables = r\"\"\"${_scope}\"\"\"\n    separate_variables = [variable for variable in all_variables.split(', ') if\n                          \"ops_\" + variable_prefix in variable]\n    logging.info(str(separate_variables).replace(\", \", \",\\n\"))\n\n\nclass SbAws:\n    \"\"\"Stonebranch Amazon Web Services Class for python\n\n    This class is written for file operations\n    to and from AWS\n\n    Attributes:\n        _storage_client: keeps the resource identifier\n        _library_version: keeps the class library version\n        _region_name: region name\n    \"\"\"\n\n    def __init__(self,\n                 endpoint_url,\n                 aws_access_key_id,\n                 aws_secret_access_key,\n                 role_arn,\n                 region_name,\n                 use_proxy=\"0\",\n                 proxy_type=\"http\",\n                 proxy_user=None,\n                 proxy_passwd=None,\n                 proxy_host=None,\n                 proxy_port=None):\n        \"\"\"Initiates the class instance\n\n        Initiates the class instance with with the given parameters\n\n        Args:\n            endpoint_url : MINIO endpoint\n            aws_access_key_id: Aws access key id\n            aws_secret_access_key: Aws access key\n            role_arn: role arn for rbac\n            region_name: Region name\n            use_proxy: proxy use flag, 0 or 1\n            proxy_type: proxy type, http or https\n            proxy_user: proxy user information\n            proxy_passwd: proxy password information\n            proxy_host: proxy host information\n            proxy_port: proxy port information\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        self._storage_client = None\n        self._storage_resource = None\n        self._storage_session = None\n        self._library_version = \"1.1\"\n        logging.info(\n            \"AWS SB library version \" + self._library_version)\n        self._region_name = region_name\n        self.connect_aws(endpoint_url,\n                         aws_access_key_id,\n                         aws_secret_access_key,\n                         role_arn,\n                         region_name,\n                         use_proxy,\n                         proxy_type,\n                         proxy_user,\n                         proxy_passwd,\n                         proxy_host,\n                         proxy_port)\n\n    def __del__(self):\n        \"\"\"Destructor of the class instance\"\"\"\n        self._storage_client = None\n        self._storage_resource = None\n        self._storage_session = None\n\n    def connect_aws(self, endpoint_url,\n                    aws_access_key_id,\n                    aws_secret_access_key,\n                    role_arn,\n                    region_name,\n                    use_proxy=\"0\",\n                    proxy_type=\"http\",\n                    proxy_user=None,\n                    proxy_passwd=None,\n                    proxy_host=None,\n                    proxy_port=None):\n        \"\"\"Connects to cloud.\n\n        Connects to the cloud with or without proxy\n        Assigns the resource id to _storage_client\n\n        Args:\n            endpoint_url: end point to MINIO\n            aws_access_key_id: Aws access key id\n            aws_secret_access_key: Aws access key\n            role_arn: role arn for rbac\n            region_name: Region name\n            use_proxy: proxy use flag, 0 or 1\n            proxy_type: proxy type, http or https\n            proxy_user: proxy user information\n            proxy_passwd: proxy password information\n            proxy_host: proxy host information\n            proxy_port: proxy port information\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        logging.debug('Establishing connection')\n        proxy_config_str = None\n        proxy_string = \"\"\n        use_proxy_string = \"\"\n        if use_proxy in \"Yes,true,True,1\":\n            # connection via Proxy\n            logging.info('S3 Connection via Proxy: %s:%s' % (\n                proxy_host, proxy_port))\n            if proxy_type == \"https_with_password\":\n                proxy_string = \"https://%s:%s@%s:%s\" % (\n                    proxy_user, proxy_passwd, proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'https': '%s' % proxy_string}\n            elif proxy_type == \"https\":\n                proxy_string = \"https://%s:%s\" % (\n                    proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'https': '%s' % proxy_string}\n            elif proxy_type == \"http_with_password\":\n                proxy_string = \"http://%s:%s@%s:%s\" % (\n                    proxy_user, proxy_passwd, proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'http': '%s' % proxy_string}\n            else:\n                proxy_string = \"http://%s:%s\" % (\n                    proxy_host, proxy_port)\n                logging.debug(\"Setting Proxy: %s\" % proxy_string)\n                use_proxy_string = {'http': '%s' % proxy_string}\n        else:\n            # connection without Proxy\n            # Create a S3 client, provide the AWS credentials, provide proxy\n            logging.info('Direct S3 Connection without Proxy')\n        if proxy_string:\n            proxy_config_str = Config(proxies=use_proxy_string)\n            logging.info('Proxy Config: %s' % str(use_proxy_string))\n        if role_arn:\n            logging.info('Authentication RBAC')\n            sts_client = boto3.client('sts',\n                                      aws_access_key_id=aws_access_key_id,\n                                      aws_secret_access_key=aws_secret_access_key,\n                                      config=proxy_config_str)\n            assumed_role_object = sts_client.assume_role(\n                RoleArn=role_arn,\n                RoleSessionName=\"AssumeRoleSession1\"\n            )\n            credentials = assumed_role_object['Credentials']\n            s3client = boto3.client(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=f['AccessKeyId'],\n                aws_secret_access_key=credentials['SecretAccessKey'],\n                aws_session_token=credentials['SessionToken'],\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_client = s3client\n            s3resource = boto3.resource(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=credentials['AccessKeyId'],\n                aws_secret_access_key=credentials['SecretAccessKey'],\n                aws_session_token=credentials['SessionToken'],\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_resource = s3resource\n        else:\n            logging.info('Authentication Access Key')\n            s3client = boto3.client(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=aws_access_key_id,\n                aws_secret_access_key=aws_secret_access_key,\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_client = s3client\n            s3resource = boto3.resource(\n                's3',\n                endpoint_url=endpoint_url,\n                aws_access_key_id=aws_access_key_id,\n                aws_secret_access_key=aws_secret_access_key,\n                region_name=region_name,\n                config=proxy_config_str)\n            self._storage_resource = s3resource\n\n    def create_object_store(self, bucket_name):\n        \"\"\"Creates a bucket in S3.\n\n        Creates a bucket in S3 if it does not exist\n\n        Args:\n            bucket_name: bucket name to be created\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.meta.client.head_bucket(Bucket='%s' %\n                                                                  bucket_name)\n            logging.error('bucket: %s already exist' % bucket_name)\n            exit(1)\n        except botocore.exceptions.ClientError as e:\n            # If a client error is thrown, then check that it was a 404 error.\n            # If was a 404 error, then bucket does not exist, will be created\n            error_code = int(e.response['Error']['Code'])\n            if error_code == 403:\n                logging.error(\n                    'bucket: %s is a Private Bucket. Forbidden Access!' %\n                    bucket_name)\n                exit(1)\n            elif error_code == 404:\n                logging.info('bucket: %s does not exist and will be created.' %\n                             bucket_name)\n                try:\n                    response = self._storage_resource.create_bucket(\n                        Bucket='%s' % bucket_name,\n                        CreateBucketConfiguration={\n                            'LocationConstraint': self._region_name})\n                    logging.info('bucket: %s created. response: %s' %\n                                 (bucket_name, response))\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n\n    def delete_object_store(self, bucket_name):\n        \"\"\"Deletes a bucket in S3.\n\n        Deletes a bucket in S3 if it exists and is empty\n\n        Args:\n            bucket_name: bucket name to be deleted\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_client.delete_bucket(Bucket='%s' % bucket_name)\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchBucket':\n                logging.info(' bucket %s does not exist' % bucket_name)\n                exit(1)\n            elif e.response['Error']['Code'] == 'BucketNotEmpty':\n                logging.info(' bucket %s is not empty' % bucket_name)\n                exit(1)\n            else:\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info(' bucket %s deleted' % bucket_name)\n\n    def list_object_stores(self):\n        \"\"\"Lists all the buckets available.\n\n        Lists all the buckets available\n\n        Args:\n            -\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        for bucket in self._storage_resource.buckets.all():\n            logging.info(bucket.name)\n\n    def __check_file_exist_in_object_store(self, key, bucket_name):\n        \"\"\"Checks for file in S3 bucket.\n\n        Checks if file is in S3 bucket\n\n        Args:\n            bucket_name: bucket name\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.Object('%s' % bucket_name, '%s' % key).load()\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == \"404\":\n                logging.debug('Key: %s does not exist' % key)\n                return False\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info('Key: %s already exist' % key)\n            return True\n\n    def copy_all_files_to_object_store(self, source_file,\n                                       bucket_name,\n                                       prefix,\n                                       overwrite=\"true\",\n                                       operation=\"copy\"):\n        \"\"\"Copies all files to S3.\n\n        Copies all files matching the pattern to S3\n\n        Args:\n            source_file: source file with unix pattern\n            bucket_name: bucket name\n            prefix: prefix to be added to key\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        dir_name, filename = os.path.split(os.path.abspath(source_file))\n        files = fnmatch.filter(os.listdir(dir_name), filename)\n        if not files:\n            logging.error('No file(s) found! %s' % filename)\n            exit(1)\n        logging.info(\"files matching:\" + str(files))\n        transfer_success = True\n        stripped_prefix = prefix.lstrip(r\" /\\ \").strip()\n        for file in files:\n            full_path = dir_name + \"/\" + file\n            if stripped_prefix:\n                file_with_prefix = stripped_prefix + \"/\" + file\n            else:\n                file_with_prefix = file\n            if self.__copy_file_to_object_store_param(full_path,\n                                                      bucket_name,\n                                                      file_with_prefix,\n                                                      overwrite) is True:\n                if operation == \"move\":\n                    self.delete_file_on_disk(full_path)\n            else:\n                transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n\n    def __copy_file_to_object_store_param(self,\n                                          full_path,\n                                          bucket_name,\n                                          target_file_name,\n                                          overwrite):\n        \"\"\"Copies file to S3 target bucket.\n\n        Copies source file in parameter to S3 target bucket\n\n        Args:\n            full_path: source file path\n            bucket_name: bucket name\n            target_file_name: target file name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        if not target_file_name.strip():\n            dir_name, file_name = os.path.split(os.path.abspath(full_path))\n        else:\n            file_name = target_file_name\n\n        if self.__check_file_exist_in_object_store(file_name, bucket_name):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info(\n                    'Key: %s exists and '\n                    'will be overwritten due to overwrite flag set to %s' %\n                    (file_name, overwrite))\n                try:\n                    self._storage_client.upload_file('%s' % full_path,\n                                                     bucket_name,\n                                                     file_name)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'Key: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (file_name, file_name + timestamp))\n                try:\n                    self._storage_client.upload_file('%s' % full_path,\n                                                     bucket_name,\n                                                     file_name + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % file_name)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                self._storage_client.upload_file('%s' %\n                                                 full_path,\n                                                 bucket_name,\n                                                 file_name)\n            except botocore.exceptions.ClientError as e:\n                logging.error(e)\n                exit(1)\n            logging.info(\n                'Finished uploading file: %s, to bucket: %s as key: %s' %\n                (full_path, bucket_name, file_name))\n        return True\n\n    @staticmethod\n    def delete_file_on_disk(file_name):\n        \"\"\"Delete a file that exists on disk.\n\n        Deletes a file that exists on local disk\n\n        Args:\n            file_name: file name to be checked\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            os.remove(file_name)\n        except OSError as e:  # operation failed, report it back to the user\n            logging.error(\"Error: %s - %s.\" % (e.filename, e.strerror))\n            return False\n        else:\n            logging.info(\"File %s deleted successfully\" % file_name)\n            return True\n\n    def download_all_files_from_object_store(self,\n                                             in_target_directory,\n                                             bucket_name,\n                                             key_file,\n                                             overwrite=\"true\",\n                                             operation=\"copy\"):\n        \"\"\"Downloads all files from S3.\n\n        Downloads all files matching the pattern from S3\n\n        Args:\n            in_target_directory: target file with path and with unix pattern\n            bucket_name: bucket name\n            key_file: file name\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        if not self.check_directory_exist_writeable_disk(in_target_directory):\n            exit(1)\n        files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n        transfer_success = True\n        # download file into current directory\n        downloaded = False\n        for fb_object in files_bucket.objects.all():\n            # split object.key into path and file name\n            path, filename = os.path.split(fb_object.key)\n            if fnmatch.fnmatch(fb_object.key, key_file):\n                logging.debug(fb_object.key)\n                if self.__download_file_from_object_store_param(bucket_name,\n                                                                fb_object.key,\n                                                                in_target_directory,\n                                                                filename,\n                                                                overwrite) is True:\n                    downloaded = True\n                    if operation == \"move\":\n                        self.__delete_object_from_object_store(bucket_name,\n                                                       fb_object.key)\n                else:\n                    transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n        if downloaded is False:\n            logging.error('No key(s) found! %s' % key_file)\n            exit(1)\n\n    @staticmethod\n    def check_file_exists_disk(file_name):\n        \"\"\"Checks if a file exists on disk.\n\n        Checks if a file exists on local disk\n\n        Args:\n            file_name: file name to be checked\n\n        Returns:\n            True if the file exists\n            False if the file does not exist\n\n        Raises:\n            -\n        \"\"\"\n        if os.path.isfile(file_name):\n            logging.debug('File exists:' + file_name)\n            return True\n        else:\n            logging.debug('File does not exist: ' + file_name)\n            return False\n\n    @staticmethod\n    def check_directory_exist_writeable_disk(directory_name):\n        \"\"\"Checks if a directory exists and is writeable on disk.\n\n        Checks if a directory exists and is writeable on local disk\n\n        Args:\n            directory_name: directory name to be checked\n\n        Returns:\n            True if the directory exists and is writeable\n            False if the directory does not exist or not is writeable\n\n        Raises:\n            -\n        \"\"\"\n        if not os.path.exists(directory_name):\n            logging.error('Directory does not exist: ' + directory_name)\n            return False\n        elif os.access(directory_name, os.W_OK):\n            logging.debug('Directory is writeable: ' + directory_name)\n            return True\n        else:\n            logging.error('Directory is not writeable: ' + directory_name)\n            return False\n\n    def __download_file_from_object_store_param(self,\n                                                bucket_name,\n                                                key,\n                                                dir_name,\n                                                file,\n                                                overwrite):\n        \"\"\"Downloads file from S3.\n\n        Downloads file from S3 to dir_name/file\n\n        Args:\n            bucket_name: bucket name\n            key: source file name\n            dir_name: target directory path\n            file: target file name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                adds an index \" (i)\" up to 16 like windows\n                    if the value is \"Rename\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        target_full_path = os.path.join(dir_name, file)\n        # Download file from S3 source bucket\n        if self.check_file_exists_disk(target_full_path):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info('File: %s exists and '\n                             'will be overwritten due to '\n                             'overwrite flag set to %s' %\n                             (target_full_path, overwrite))\n                try:\n                    logging.info('Start Downloading File: %s ,'\n                                 'from bucket: %s to file: %s' %\n                                 (key, bucket_name, target_full_path))\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % target_full_path)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error('The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n                else:\n                    logging.info('Downloading File: %s ,'\n                                 'from bucket: %s to file: %s finished' %\n                                 (key, bucket_name, target_full_path))\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'File: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (target_full_path, target_full_path + timestamp))\n                try:\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % target_full_path + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error('The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n                else:\n                    logging.info(\n                        'Downloading File: %s ,from bucket: %s '\n                        'to file: %s finished' %\n                        (key, bucket_name, target_full_path))\n            elif overwrite in \"Rename\":\n                file_name, file_extension = os.path.splitext(target_full_path)\n                new_target_file_name = \"\"\n                for index in range(1, 17):\n                    new_file_name = file_name + \" (%d)%s\" % (\n                        index, file_extension)\n                    logging.debug(\"new file: \" + new_file_name)\n                    if os.path.isfile(new_file_name):\n                        logging.debug(new_file_name + \" already exists\")\n                    else:\n                        new_target_file_name = new_file_name\n                        logging.info(\n                            'File: %s exists and '\n                            'new one will be renamed and written as %s' %\n                            (target_full_path, new_file_name))\n                        break\n                if not new_target_file_name.strip():\n                    logging.error(\n                        \"Max rename index limit (%d) reached, exiting\" % index)\n                    return False\n                try:\n                    self._storage_resource.Bucket(\n                        '%s' % bucket_name).download_file(\n                        '%s' % key, '%s' % new_target_file_name)\n                except botocore.exceptions.ClientError as e:\n                    if e.response['Error']['Code'] == \"404\":\n                        logging.error(\n                            'The object does not exists: %s' % key)\n                        exit(404)\n                    else:\n                        raise\n                except Exception as unknown_exception:\n                    logging.error(unknown_exception)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % target_full_path)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                logging.info(\n                    'Start Downloading File: %s ,'\n                    'from bucket: %s to file: %s' %\n                    (key, bucket_name, target_full_path))\n                self._storage_resource.Bucket(\n                    '%s' % bucket_name).download_file('%s' % key,\n                                                      '%s' % target_full_path)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    logging.error('The object does not exists: %s' % key)\n                    exit(404)\n                else:\n                    raise\n            except Exception as unknown_exception:\n                logging.error(unknown_exception)\n                exit(1)\n            else:\n                logging.info(\n                    'Downloading File: %s ,from bucket: %s to file: '\n                    '%s finished' %\n                    (key, bucket_name, target_full_path))\n        return True\n\n    def delete_all_objects_from_object_store(self,\n                                             bucket_name,\n                                             key_file):\n        \"\"\"Deletes all files from S3.\n\n        Deletes all files matching the pattern from S3\n\n        Args:\n            bucket_name: bucket name\n            key_file: file name\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n\n        files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n        matched_object = False\n        for fb_object in files_bucket.objects.all():\n            logging.debug(fb_object.key)\n            # split object.key into path and file name\n            if fnmatch.fnmatch(fb_object.key, key_file):\n                matched_object = True\n                self.__delete_object_from_object_store(bucket_name, fb_object.key)\n        if not matched_object:\n            pattern_chars = [\"*\", \"?\", \"[\", \"]\"]\n            if any(pattern_char in key_file for pattern_char in pattern_chars):\n                logging.error(\n                    \"delete: cannot remove '%s': No matching keys found\" % key_file)\n            else:\n                logging.error(\n                    \"delete: cannot remove '%s': No such key found\" % key_file)\n            exit(1)\n\n    def __delete_object_from_object_store(self, bucket_name, key):\n        \"\"\"Deletes file from S3.\n\n        Deletes key from S3 bucket\n\n        Args:\n            bucket_name: bucket name\n            key: source file name\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        try:\n            self._storage_resource.Object('%s' % bucket_name, '%s' % key).get()\n        except botocore.exceptions.ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchKey':\n                logging.error(' The object: %s does not exists' % key)\n                exit(403)\n            else:\n                logging.info('############################')\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info(': Key deleted: %s, from Bucket: %s' %\n                         (key, bucket_name))\n            self._storage_resource.Object('%s' % bucket_name,\n                                          '%s' % key).delete()\n\n    def list_object_store_content(self, bucket_name, prefix, s3_key,\n                                  show_details):\n        \"\"\"Lists the content of the bucket.\n\n        Lists the content of the bucket incl. prefix for further selection.\n        The prefix limits the results to only those keys that begin with the specified prefix\n\n        Args:\n            bucket_name: bucket name\n            prefix: prefix to limit result set\n            s3_key: s3 key or pattern to match and list the keys\n            show_details: list key, LastModified timestamp, size\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        # ## List the content of the bucket\n        my_bucket = self._storage_resource.Bucket(bucket_name)\n        stripped_prefix = prefix.lstrip(r\" /\\ \").strip()\n        stripped_key = s3_key.strip()\n        if not stripped_key:\n            stripped_key = \"*\"\n        if stripped_prefix:\n            key_with_prefix = stripped_prefix + \"/\" + stripped_key\n        else:\n            key_with_prefix = stripped_key\n        logging.debug(\"key_with_prefix: \" + key_with_prefix)\n        for s3_file in my_bucket.objects.all():\n            if key_with_prefix:\n                if fnmatch.fnmatch(s3_file.key, key_with_prefix):\n                    if show_details == \"true\":\n                        logging.info(\n                            f\"{s3_file.key}\\t {s3_file.last_modified}\\t {s3_file.size}\")\n                    else:\n                        logging.info(s3_file.key)\n            else:\n                logging.info(s3_file.key)\n\n    def check_file_on_object_store(self, bucket_name, s3key):\n        # check for file in S3 bucket\n        try:\n            self._storage_resource.Object(bucket_name, s3key).load()\n        except Exception as e:\n            if e.response['Error']['Code'] == \"404\":\n                logging.error('Object: %s not found in bucket: %s' % (\n                    s3key, bucket_name))\n                exit(1)\n            else:\n                raise\n        except Exception as unknown_exception:\n            logging.error(unknown_exception)\n            exit(1)\n        else:\n            logging.info('Object: %s found in bucket: %s' % (\n                s3key, bucket_name))\n\n    def check_file_on_object_store_new(self, bucket_name, s3key, interval=\"0\"):\n        \"\"\"Checks if file exist in S3 bucket.\n\n        Monitoring function that checks the file in S3 bucket\n        Sleeps with the given interval time\n\n        Args:\n            bucket_name: bucket name\n            s3key: file name unix pattern to expect\n            interval: sleeps in a loop with this interval\n                does not loop if the interval is \"0\"\n\n        Returns:\n            True whenever a file is found if the interval is \"1\"\n\n        Raises:\n            -\n        \"\"\"\n        files_bucket = None\n        found = False  # allow for at least one iteration\n        while not found:\n            try:\n                files_bucket = self._storage_resource.Bucket('%s' % bucket_name)\n            except botocore.exceptions.ClientError as e:\n                if e.response['Error']['Code'] == \"404\":\n                    found = False\n                    if interval == \"0\":\n                        logging.error('Object: %s not found in bucket: %s' % (\n                            s3key, bucket_name))\n                        exit(1)\n                    else:\n                        time.sleep(float(interval))\n                else:\n                    raise\n            except Exception as unknown_exception:\n                logging.error(unknown_exception)\n                exit(1)\n            else:\n                # download file into current directory\n                for fb_object in files_bucket.objects.all():\n                    # split object.key into path and file name\n                    path, filename = os.path.split(fb_object.key)\n                    if fnmatch.fnmatch(filename, s3key):\n                        logging.info('Object: %s found in bucket: %s' %\n                                     (filename, bucket_name))\n                        logging.info('LAUNCHTASK for %s in bucket: %s' %\n                                     (filename, bucket_name))\n                        found = True\n\n    def copy_all_objects_to_object_store(self,\n                                         source_object_name,\n                                         bucket_name,\n                                         target_bucket_name,\n                                         overwrite=\"true\",\n                                         operation=\"copy\"):\n        \"\"\"Copies all objects from a bucket to another.\n\n        Copies all objects matching the pattern to another bucket\n\n        Args:\n            source_object_name: source object name\n            bucket_name: bucket name\n            target_bucket_name: target bucket name\n            overwrite: overwrite flag for the next function\n            operation: copy or move\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n        my_bucket = self._storage_resource.Bucket(bucket_name)\n        for s3_file in my_bucket.objects.all():\n            logging.info(s3_file.key)\n        all_key_objects = my_bucket.objects.all()\n        all_keys = [s3_key.key for s3_key in all_key_objects]\n        all_matching_keys = fnmatch.filter(all_keys, source_object_name)\n        if not all_matching_keys:\n            logging.error('No key(s) found! %s' % source_object_name)\n            exit(1)\n        logging.info(\"keys matching:\" + str(all_matching_keys))\n        transfer_success = True\n        for matching_key in all_matching_keys:\n            logging.info(\"copying key: \" + str(matching_key))\n            if self.__copy_object_to_object_store_param(matching_key,\n                                                        bucket_name,\n                                                        target_bucket_name,\n                                                        overwrite) is True:\n                if operation == \"move\":\n                    logging.warning(\"move not supported!\")\n                    pass\n            else:\n                transfer_success = False\n        if transfer_success is False:\n            logging.error('There has been some errors!')\n            exit(1)\n\n    def __copy_object_to_object_store_param(self,\n                                            source_object_name,\n                                            bucket_name,\n                                            target_bucket_name,\n                                            overwrite):\n        \"\"\"Copies object from bucket to S3 target bucket.\n\n        Copies source file in parameter to S3 target bucket\n\n        Args:\n            source_object_name: source object name\n            bucket_name: bucket name\n            target_bucket_name: target bucket name\n            overwrite:\n                overwrites if the value is in \"true,True,replace,Overwrite\",\n                adds a timestamp \".%Y-%m-%dT%H:%M:%S%z\" to the file name\n                    if the value is in \"wt,Timestamp\"\n                returns False if the value is in \"false,False,new\"\n                exits with an error if none of the above\n\n        Returns:\n            -\n\n        Raises:\n            -\n        \"\"\"\n\n        copy_source = {\n            'Bucket': bucket_name,\n            'Key': source_object_name\n        }\n        target_bucket = self._storage_resource.Bucket(target_bucket_name)\n        if self.__check_file_exist_in_object_store(source_object_name,\n                                                   target_bucket_name):\n            if overwrite in \"true,True,replace,Overwrite\":\n                logging.info(\n                    'Key: %s exists and '\n                    'will be overwritten due to overwrite flag set to %s' %\n                    (source_object_name, overwrite))\n                try:\n                    target_bucket.copy(copy_source, source_object_name)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"wt,Timestamp\":\n                timestamp = str(\n                    datetime.datetime.now().strftime(\".%Y-%m-%dT%H:%M:%S%z\"))\n                logging.info(\n                    'Key: %s exists and '\n                    'new one will be named with timestamp as %s' %\n                    (source_object_name, source_object_name + timestamp))\n                try:\n                    target_bucket.copy(copy_source,\n                                       source_object_name + timestamp)\n                except botocore.exceptions.ClientError as e:\n                    logging.error(e)\n                    exit(1)\n            elif overwrite in \"false,False,new\":\n                logging.error(\n                    'File: %s exists and will not be overwritten, '\n                    'otherwise please change Write Options' % source_object_name)\n                return False\n            else:\n                logging.error('Unknown overwrite option, exiting')\n                exit(1)\n        else:\n            try:\n                target_bucket.copy(copy_source, source_object_name)\n            except botocore.exceptions.ClientError as e:\n                logging.error(e)\n                exit(1)\n            logging.info(\n                'Finished copying key: %s, to bucket: %s' %\n                (source_object_name, target_bucket_name))\n        return True\n\n\nif __name__ == '__main__':\n    main()\n",
    "sysId": "bb9fb8be0fb34ac1b5333f33f4779ba7",
    "useCommonScript": false,
    "variablePrefix": "var",
    "waitForOutput": false
}